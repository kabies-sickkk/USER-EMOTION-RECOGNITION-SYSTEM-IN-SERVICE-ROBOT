import os
import cv2
import numpy as np
import matplotlib.pyplot as plt
import pickle

from sklearn.svm import SVC
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay
from sklearn.decomposition import PCA
from skimage.feature import hog, local_binary_pattern

import dlib

# ==== Th√¥ng s·ªë LBP ====
LBP_RADIUS = 1
LBP_POINTS = 8 * LBP_RADIUS
LBP_METHOD = 'uniform'

# ==== Load Dlib Predictor ====
predictor_path = r'E:\Mayhoc_ungdung\Report\shape_predictor_68_face_landmarks.dat'
detector = dlib.get_frontal_face_detector()
predictor = dlib.shape_predictor(predictor_path)

# ==== C√°c h√†m tr√≠ch xu·∫•t ƒë·∫∑c tr∆∞ng ====
def extract_lbp(img):
    lbp = local_binary_pattern(img, LBP_POINTS, LBP_RADIUS, method=LBP_METHOD)
    hist, _ = np.histogram(lbp.ravel(), bins=np.arange(0, LBP_POINTS + 3), range=(0, LBP_POINTS + 2))
    hist = hist.astype("float")
    hist /= (hist.sum() + 1e-7)
    return hist

def extract_landmarks(img):
    rects = detector(img, 1)
    if len(rects) == 0:
        return np.zeros(68 * 2)
    shape = predictor(img, rects[0])
    coords = np.array([[p.x, p.y] for p in shape.parts()]).flatten()
    return coords

def extract_hog(img):
    features = hog(img,
                   orientations=9,
                   pixels_per_cell=(8, 8),
                   cells_per_block=(2, 2),
                   block_norm='L2-Hys',
                   visualize=False)
    return features

# ==== H√†m ti·ªÅn x·ª≠ l√Ω v√† tr√≠ch xu·∫•t ƒë·∫∑c tr∆∞ng ====
def preprocess_and_extract_features(img, method='hog+lbp+landmark', image_size=(48, 48)):
    img = cv2.resize(img, image_size)
    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))
    img = clahe.apply(img)
    img = cv2.GaussianBlur(img, (3, 3), 0)

    features = []
    if 'hog' in method:
        features.append(extract_hog(img))
    if 'lbp' in method:
        features.append(extract_lbp(img))
    if 'landmark' in method:
        features.append(extract_landmarks(img))

    return np.concatenate(features)

# ==== Load d·ªØ li·ªáu ====
def load_data(base_path, method):
    X, y = [], []
    labels = sorted(os.listdir(base_path))
    for label in labels:
        folder_path = os.path.join(base_path, label)
        for filename in os.listdir(folder_path):
            img_path = os.path.join(folder_path, filename)
            img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)
            if img is not None:
                features = preprocess_and_extract_features(img, method)
                X.append(features)
                y.append(label)
    return np.array(X), np.array(y), labels

# ==== Hu·∫•n luy·ªán & ƒë√°nh gi√° ====
def train_and_evaluate(train_path, test_path, method_name, model_save_path=None):
    print(f"\nüîß ƒêang ch·∫°y ph∆∞∆°ng ph√°p: {method_name}")

    print("üì• ƒêang t·∫£i v√† x·ª≠ l√Ω d·ªØ li·ªáu hu·∫•n luy·ªán...")
    X_train, y_train, labels = load_data(train_path, method=method_name)

    print("üì• ƒêang t·∫£i v√† x·ª≠ l√Ω d·ªØ li·ªáu ki·ªÉm th·ª≠...")
    X_test, y_test, _ = load_data(test_path, method=method_name)

    print("‚öñÔ∏è Chu·∫©n h√≥a d·ªØ li·ªáu...")
    scaler = StandardScaler()
    X_train_scaled = scaler.fit_transform(X_train)
    X_test_scaled = scaler.transform(X_test)

    print("üìâ Gi·∫£m chi·ªÅu b·∫±ng PCA...")
    pca = PCA(n_components=0.97)
    X_train_pca = pca.fit_transform(X_train_scaled)
    X_test_pca = pca.transform(X_test_scaled)
    print(f"‚û°Ô∏è S·ªë chi·ªÅu c√≤n l·∫°i: {pca.n_components_}")

    print("üß† Hu·∫•n luy·ªán SVM...")
    clf = SVC(kernel='rbf', C=100.0, gamma='scale', class_weight='balanced')
    clf.fit(X_train_pca, y_train)

    print("üîç ƒê√°nh gi√° m√¥ h√¨nh...")
    y_pred = clf.predict(X_test_pca)
    print("\nüìä Classification Report:\n")
    print(classification_report(y_test, y_pred))

    cm = confusion_matrix(y_test, y_pred, labels=labels)
    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=labels)
    disp.plot(cmap=plt.cm.Blues, xticks_rotation=45)
    plt.title(f"Confusion Matrix - {method_name.upper()}")
    plt.tight_layout()
    plt.show()

    if model_save_path:
        with open(model_save_path, 'wb') as f:
            pickle.dump({'model': clf, 'scaler': scaler, 'pca': pca, 'labels': labels}, f)
        print(f"‚úÖ M√¥ h√¨nh ƒë√£ l∆∞u: {model_save_path}")

# ==== Th·ª≠ nghi·ªám c√°c t·ªï h·ª£p ƒë·∫∑c tr∆∞ng ====
train_path = r'E:\Mayhoc_ungdung\Report\train'
test_path = r'E:\Mayhoc_ungdung\Report\test'

feature_combinations = [
    'lbp',
    'landmark',
    'lbp+landmark',
    'hog+lbp',
    'hog+landmark',
    'hog+lbp+landmark'
]

for method in feature_combinations:
    model_filename = f"svm_emotion_model_{method.replace('+', '_')}.pkl"
    train_and_evaluate(train_path, test_path, method, model_save_path=model_filename)
