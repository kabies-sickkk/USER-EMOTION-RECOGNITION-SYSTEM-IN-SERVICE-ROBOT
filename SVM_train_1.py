import os
import cv2
import numpy as np
import matplotlib.pyplot as plt
import pickle

from sklearn.svm import SVC
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay
from sklearn.decomposition import PCA
from skimage.feature import hog, local_binary_pattern

import dlib

# ==== Thi·∫øt l·∫≠p th√¥ng s·ªë ====
LBP_RADIUS = 1
LBP_POINTS = 8 * LBP_RADIUS
LBP_METHOD = 'uniform'

predictor_path = r'E:\Mayhoc_ungdung\Report\shape_predictor_68_face_landmarks.dat'
detector = dlib.get_frontal_face_detector()
predictor = dlib.shape_predictor(predictor_path)

# ==== H√†m tr√≠ch xu·∫•t landmark ====
def extract_landmarks(img):
    rects = detector(img, 1)
    if len(rects) == 0:
        return np.zeros(68*2)
    shape = predictor(img, rects[0])
    coords = np.array([[p.x, p.y] for p in shape.parts()]).flatten()
    return coords

# ==== H√†m tr√≠ch xu·∫•t LBP ====
def extract_lbp(img):
    lbp = local_binary_pattern(img, LBP_POINTS, LBP_RADIUS, method=LBP_METHOD)
    (hist, _) = np.histogram(lbp.ravel(), bins=np.arange(0, LBP_POINTS + 3), range=(0, LBP_POINTS + 2))
    hist = hist.astype("float")
    hist /= (hist.sum() + 1e-7)
    return hist

# ==== Ti·ªÅn x·ª≠ l√Ω + Tr√≠ch xu·∫•t HOG + LBP + Landmark ====
def preprocess_and_extract_features(img, image_size=(48, 48)):
    img = cv2.resize(img, image_size)
    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))
    img = clahe.apply(img)
    img = cv2.GaussianBlur(img, (3, 3), 0)

    # Tr√≠ch xu·∫•t HOG
    hog_features = hog(img,
                       orientations=9,
                       pixels_per_cell=(8, 8),
                       cells_per_block=(2, 2),
                       block_norm='L2-Hys',
                       visualize=False)

    # Tr√≠ch xu·∫•t LBP
    lbp_features = extract_lbp(img)

    # Tr√≠ch xu·∫•t Landmark
    landmarks = extract_landmarks(img)

    return np.concatenate((hog_features, lbp_features, landmarks))

# ==== N·∫°p d·ªØ li·ªáu t·ª´ th∆∞ m·ª•c ====
def load_data_from_folder(base_path):
    X = []
    y = []
    labels = sorted(os.listdir(base_path))
    for label in labels:
        folder_path = os.path.join(base_path, label)
        for filename in os.listdir(folder_path):
            img_path = os.path.join(folder_path, filename)
            img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)
            if img is not None:
                features = preprocess_and_extract_features(img)
                X.append(features)
                y.append(label)
    return np.array(X), np.array(y), labels

# ==== ƒê∆∞·ªùng d·∫´n d·ªØ li·ªáu ====
train_path = r'E:\Mayhoc_ungdung\Report\train'
test_path = r'E:\Mayhoc_ungdung\Report\test'

# ==== X·ª≠ l√Ω d·ªØ li·ªáu ====
print("üîÑ ƒêang x·ª≠ l√Ω d·ªØ li·ªáu hu·∫•n luy·ªán...")
X_train, y_train, label_names = load_data_from_folder(train_path)

print("üîÑ ƒêang x·ª≠ l√Ω d·ªØ li·ªáu ki·ªÉm th·ª≠...")
X_test, y_test, _ = load_data_from_folder(test_path)

# ==== Chu·∫©n h√≥a d·ªØ li·ªáu ====
print("‚öñÔ∏è ƒêang chu·∫©n h√≥a d·ªØ li·ªáu...")
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# ==== PCA ƒë·ªÉ gi·∫£m chi·ªÅu ====
print("üìâ ƒêang gi·∫£m chi·ªÅu b·∫±ng PCA...")
pca = PCA(n_components=0.97)
X_train_pca = pca.fit_transform(X_train_scaled)
X_test_pca = pca.transform(X_test_scaled)

print(f"‚úÖ S·ªë chi·ªÅu sau PCA: {pca.n_components_}")

# ==== Hu·∫•n luy·ªán m√¥ h√¨nh SVM ====
print("üß† ƒêang hu·∫•n luy·ªán m√¥ h√¨nh SVM...")
clf = SVC(kernel='rbf', C=100.0, gamma='scale', class_weight='balanced')
clf.fit(X_train_pca, y_train)

# ==== D·ª± ƒëo√°n v√† ƒë√°nh gi√° ====
print("üîç ƒêang d·ª± ƒëo√°n v√† ƒë√°nh gi√° m√¥ h√¨nh...")
y_pred = clf.predict(X_test_pca)
print("\nüìä Classification Report:\n")
print(classification_report(y_test, y_pred))

# ==== Confusion matrix ====
cm = confusion_matrix(y_test, y_pred, labels=label_names)
disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=label_names)
disp.plot(cmap=plt.cm.Blues, xticks_rotation=45)
plt.title("Confusion Matrix")
plt.tight_layout()
plt.show()

# ==== L∆∞u m√¥ h√¨nh ====
with open('svm_emotion_model_6.pkl', 'wb') as f:
    pickle.dump({
        'model': clf,
        'pca': pca,
        'scaler': scaler,
        'labels': label_names
    }, f)

print("‚úÖ M√¥ h√¨nh, PCA v√† scaler ƒë√£ ƒë∆∞·ª£c l∆∞u v√†o 'svm_emotion_model_6.pkl'")
